{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explaining the functions used to run the model\n",
    "\n",
    "### load_mat\n",
    "Purpose: Load data from a .mat file.\n",
    "Inputs:\n",
    "name: The name of the .mat file.\n",
    "split_real_imaginary: If True, splits the real and imaginary parts of the data.\n",
    "include_metadata: List of additional metadata to include.\n",
    "Outputs: A tuple of tensors containing the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(\n",
    "    name: str,\n",
    "    split_real_imaginary: bool = True,\n",
    "    include_metadata: List[Literal[\"fiber_fractions\"]] = []\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "    # Function to load .mat file and return tensor data\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_point_clouds\n",
    "Purpose: Load point cloud data from a file.\n",
    "Inputs:\n",
    "name: The name of the file containing point cloud data.\n",
    "Outputs: A tuple of dictionaries containing the point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_clouds(name: str) -> Tuple[Dict[int, Tensor], Dict[int, Tensor]]:\n",
    "    # Function to load point cloud data from a file\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_mags\n",
    "Purpose: Convert a complex tensor to a magnitude tensor.\n",
    "Inputs:\n",
    "voxel: A tensor containing complex values.\n",
    "Outputs: A tensor containing the magnitudes of the complex values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize\n",
    "Purpose: Visualize voxel data.\n",
    "Inputs:\n",
    "voxel: A tensor containing voxel data.\n",
    "int_range: Intensity range for visualization.\n",
    "title: Title of the plot.\n",
    "Outputs: None. This function visualizes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(voxel, int_range=[0.6,1], title='Plot'):\n",
    "    # Function to visualize voxel data\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxelDataset(Dataset)\n",
    "Purpose: Custom dataset class for handling voxel data and corresponding lines.\n",
    "Inputs:\n",
    "voxel_data: Tensor containing voxel data.\n",
    "lines: Tensor containing line data (ground truth from Hough Transform).\n",
    "Outputs: Provides methods to get the length of the dataset and to get individual data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, voxel_data, lines):\n",
    "        self.voxel_data = voxel_data\n",
    "        self.lines = lines\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.voxel_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.voxel_data[idx], self.lines[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HoughNN\n",
    "Purpose: Define a 3D CNN model for voxel data.\n",
    "Inputs:\n",
    "x: Input tensor of shape (batch_size, 1, 33, 33, 33).\n",
    "Outputs:\n",
    "Output tensor of shape (batch_size, 6) representing the line parameters [npoints, a1, a2, a3, b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoughNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HoughNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_model\n",
    "Purpose: Train the neural network model.\n",
    "Inputs:\n",
    "model: The neural network model to train.\n",
    "dataloader: DataLoader providing the training data.\n",
    "criterion: Loss function.\n",
    "optimizer: Optimizer for training.\n",
    "num_epochs: Number of epochs to train.\n",
    "Outputs: Trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.unsqueeze(1).float()  # Add channel dimension\n",
    "            targets = targets.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate_model\n",
    "Purpose: Evaluate the neural network model.\n",
    "Inputs:\n",
    "model: The neural network model to evaluate.\n",
    "dataloader: DataLoader providing the evaluation data.\n",
    "criterion: Loss function.\n",
    "Outputs: Mean Squared Error (MSE) of the model on the evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.unsqueeze(1).float()\n",
    "            targets = targets.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            mse += loss.item() * inputs.size(0)\n",
    "\n",
    "    mse /= len(dataloader.dataset)\n",
    "    return mse\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
