{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "the data will be called from 'src/loaders.py' file with the required functions. We'll use these functions to load and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Assuming these functions are implemented in src/loaders.py\n",
    "from src.loaders import load_mat, load_point_clouds, get_mags\n",
    "from src.visualize import visualize\n",
    "\n",
    "# Load clean and noisy data\n",
    "clean_voxel_data, _ = load_mat('clean_data.mat')\n",
    "noisy_voxel_data, _ = load_mat('noisy_data.mat')\n",
    "point_clouds, _ = load_point_clouds('clean_data')\n",
    "\n",
    "# Convert complex values to magnitudes\n",
    "clean_voxel_data = get_mags(clean_voxel_data)\n",
    "noisy_voxel_data = get_mags(noisy_voxel_data)\n",
    "\n",
    "# Visualize data (optional)\n",
    "visualize(clean_voxel_data[0], title='Clean Data')\n",
    "visualize(noisy_voxel_data[0], title='Noisy Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data\n",
    "Defining a custom dataset class to handle the voxel data and corresponding lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, voxel_data, lines):\n",
    "        self.voxel_data = voxel_data\n",
    "        self.lines = lines\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.voxel_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.voxel_data[idx], self.lines[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will apply Hough Transform to get ground truth lines for clean data\n",
    "### Assuming apply_hough_transform is defined elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hough_transform(voxel_data):\n",
    "    '''we can define the code here for hough transformation'''\n",
    "    lines = np.random.rand(len(voxel_data), 6)  # Example format: [npoints, a1, a2, a3, b1, b2, b3]\n",
    "    return lines\n",
    "\n",
    "clean_lines = apply_hough_transform(clean_voxel_data)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "clean_dataset = VoxelDataset(clean_voxel_data, clean_lines)\n",
    "clean_data_loader = DataLoader(clean_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "noisy_dataset = VoxelDataset(noisy_voxel_data, clean_lines)  # using clean_lines as target\n",
    "noisy_data_loader = DataLoader(noisy_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Model\n",
    "### I chose a 3D CNN model to process the voxel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HoughNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HoughNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 6)  # Output size: [npoints, a1, a2, a3, b1, b2, b3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "### Defining the training function and training the model using clean data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.unsqueeze(1).float()  # we have to add channel dimension\n",
    "            targets = targets.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HoughNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on clean data...\")\n",
    "model = train_model(model, clean_data_loader, criterion, optimizer, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model\n",
    "### Evaluating the model on noisy data and comparing it with the Hough Transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.unsqueeze(1).float()\n",
    "            targets = targets.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            mse += loss.item() * inputs.size(0)\n",
    "\n",
    "    mse /= len(dataloader.dataset)\n",
    "    return mse\n",
    "\n",
    "# Evaluate the model on noisy data\n",
    "print(\"Evaluating on noisy data...\")\n",
    "noisy_mse = evaluate_model(model, noisy_data_loader, criterion)\n",
    "print(f\"Mean Squared Error on noisy data: {noisy_mse:.4f}\")\n",
    "\n",
    "# Evaluate Hough Transform on noisy data\n",
    "noisy_lines = apply_hough_transform(noisy_voxel_data)\n",
    "hough_mse = ((noisy_lines - clean_lines)**2).mean().item()\n",
    "\n",
    "print(f\"Hough Transform MSE on noisy data: {hough_mse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
